{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ci7JfrFM3k4I"
   },
   "source": [
    "# Import the Required Dependencies \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6LD13_jJ3k4J"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "import keras \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.regularizers import l1\n",
    "import os\n",
    "import time\n",
    "from time import time\n",
    "\n",
    "def plot_learningCurve(history,num_epoch):\n",
    "  # Plot training & validation accuracy values\n",
    "  epoch_range = np.arange(1,num_epoch+1)\n",
    "  plt.plot(epoch_range, history.history['acc'])\n",
    "  plt.plot(epoch_range, history.history['val_acc'])\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot training & validation loss values\n",
    "  plt.plot(epoch_range, history.history['loss'])\n",
    "  plt.plot(epoch_range, history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "save_dir='/model/resnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GaqVr_T03XrW"
   },
   "source": [
    "## Note on Conv2D\n",
    "\n",
    "In order to implement the convolutional layers, we use the Keras implementation of Conv2D. However, in all cases, you are required to use a specific kernel initializer so that the results are predictable ( random initialization of convolutional kernel would result in unpredictable ).\n",
    "\n",
    "As such, please use the following Conv2D: \n",
    "\n",
    "Conv2D(filters=f, kernel_size=(k, k), strides=(s, s), padding=pad_type, kernel_initializer=keras.initializers.glorot_uniform(seed=0))(X)\n",
    "\n",
    "In which f,k and s denote the size of filter,kernel and stride. Pad_type denoted the padding type which can be either \"same\" or \"valid\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7eA51suF12fn"
   },
   "source": [
    "##Implementing the Identity Block \n",
    "\n",
    "We discussed the identity block in the homework description. Here we provide the details of the components that you should use to implement it. \n",
    "\n",
    "The following represents the components: \n",
    "\n",
    "First component of main path: \n",
    "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the seed for the random initialization. \n",
    "- The first BatchNorm is normalizing the channels axis. No particular argument needs to be passed.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters. \n",
    "\n",
    "Second component of main path:\n",
    "- The second CONV2D has $F_2$ filters of shape $(f,f)$ and a stride of (1,1). Its padding is \"same\". Use 0 as the seed for the random initialization. \n",
    "- The second BatchNorm is normalizing the channels axis. No particular argument needs to be passed.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters\n",
    "\n",
    "Third component of main path:\n",
    "- The third CONV2D has $F_3$ filters of shape (1,1) and a stride of (1,1). Its padding is \"valid\". Use 0 as the seed for the random initialization. \n",
    "- The third BatchNorm is normalizing the channels axis. No particular argument needs to be passed. \n",
    "- Then apply the ReLU activation function. This has no hyperparameters\n",
    "\n",
    "Final step: \n",
    "- The shortcut and the input are added together.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters\n",
    "\n",
    "Useful links:\n",
    "\n",
    "- [Conv](https://keras.io/layers/convolutional/#conv2d)\n",
    "- [BatchNorm](https://keras.io/layers/normalization/#batchnormalization)\n",
    "- For the activation, use:  `Activation('relu')(X)`\n",
    "- [Addition](https://keras.io/layers/merge/#add)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kJc-hKMN3k4P"
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 4 of homework\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path (e.g. [2,4,16])\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve Filters\n",
    "   \n",
    "\n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "   \n",
    "\n",
    "    # First component of main path\n",
    "    \n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    \n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    \n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8jSnfAHX8cUH"
   },
   "source": [
    "##Testing the Identity Block\n",
    "\n",
    "Simply run the code in the following block and report the result that is generated in your homework report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ikDdEFha3k4R"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [4, 4, 4, 8])\n",
    "    X = np.random.randn(4,4,4,8)\n",
    "    A = identity_block(A_prev, f=2, filters=[2, 4, 8])\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    res = test.run([A], feed_dict={A_prev: X})\n",
    "    print('Result = {}'.format(res[0][1][1][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQbD_ipW-06u"
   },
   "source": [
    "##Implementing the Convolutional Block \n",
    "\n",
    "We discussed the convolutional block in the homework description. Here we provide the details of the components that you should use to implement it. \n",
    "\n",
    "The following represents the components: \n",
    "\n",
    "First component of main path:\n",
    "- The first CONV2D has $F_1$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\". \n",
    "- The first BatchNorm is normalizing the channels axis. No particular argument needs to be passed.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters. \n",
    "\n",
    "Second component of main path:\n",
    "- The second CONV2D has $F_2$ filters of (f,f) and a stride of (1,1). Its padding is \"same\".\n",
    "- The second BatchNorm is normalizing the channels axis. No particular argument needs to be passed.\n",
    "- Then apply the ReLU activation function. This has no hyperparameters. \n",
    "\n",
    "Third component of main path:\n",
    "- The third CONV2D has $F_3$ filters of (1,1) and a stride of (1,1). Its padding is \"valid\".\n",
    "- The third BatchNorm is normalizing the channels axis. No particular argument needs to be passed. Note that there is no ReLU activation function in this component. \n",
    "\n",
    "Shortcut path:\n",
    "- The CONV2D has $F_3$ filters of shape (1,1) and a stride of (s,s). Its padding is \"valid\".\n",
    "- The BatchNorm is normalizing the channels axis. BatchNorm is normalizing the channels axis. No particular argument needs to be passed\n",
    "\n",
    "Final step: \n",
    "- The shortcut and the main path values are added together.\n",
    "- Then apply the ReLU activation function. This has no name and no hyperparameters. \n",
    "\n",
    "Useful links:\n",
    "\n",
    "- [Conv](https://keras.io/layers/convolutional/#conv2d)\n",
    "- [BatchNorm](https://keras.io/layers/normalization/#batchnormalization)\n",
    "- For the activation, use:  `Activation('relu')(X)`\n",
    "- [Addition](https://keras.io/layers/merge/#add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WTTaFuRa3k4V"
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters,stride=2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 5 of homework\n",
    "\n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path (e.g. [2,4,16])\n",
    "    stride -- Integer, specifying the stride to be used\n",
    "\n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve Filters\n",
    "    \n",
    "\n",
    "    # Save the input value\n",
    "   \n",
    "\n",
    "    # First component of main path \n",
    "    \n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    \n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    \n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    \n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oGITZoKUDBTs"
   },
   "source": [
    "##Testing the Convolutional Block\n",
    "\n",
    "Simply run the code in the following block and report the result that is generated in your homework report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hQQAH8UM3k4X"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.placeholder(\"float\", [4, 4, 4, 8])\n",
    "    X = np.random.randn(4,4,4,8)\n",
    "    A = convolutional_block(A_prev, f=2, filters=[2, 4, 8])\n",
    "    test.run(tf.global_variables_initializer())\n",
    "    res = test.run([A], feed_dict={A_prev: X})\n",
    "    print('Result = {}'.format(res[0][1][1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FjLuQmAOFAgm"
   },
   "source": [
    "##Implementing ResNet \n",
    "\n",
    "We discussed the ResNet architecture in the homework description ( see Figure 6 ). Here we provide further details you should use to implement it.\n",
    "The following represents ResNet components: \n",
    "\n",
    "- Zero-padding pads the input with a pad of (3,3)\n",
    "- Stage 1:\n",
    "    - The 2D Convolution has 64 filters of shape (7,7) and uses a stride of (2,2).\n",
    "    - BatchNorm is applied to the channels axis of the input.\n",
    "    - MaxPooling uses a (3,3) window and a (2,2) stride.\n",
    "- Stage 2:\n",
    "    - The convolutional block uses three set of filters of size [64,64,256], \"f\" is 3, \"s\" is 1.\n",
    "    - The 2 identity blocks use three set of filters of size [64,64,256], \"f\" is 3.\n",
    "- Stage 3:\n",
    "    - The convolutional block uses three set of filters of size [128,128,512], \"f\" is 3, \"s\" is 2.\n",
    "    - The 3 identity blocks use three set of filters of size [128,128,512], \"f\" is 3.\n",
    "- Stage 4:\n",
    "    - The convolutional block uses three set of filters of size [256, 256, 1024], \"f\" is 3, \"s\" is 2.\n",
    "    - The 5 identity blocks use three set of filters of size [256, 256, 1024], \"f\" is 3.\n",
    "- Stage 5:\n",
    "    - The convolutional block uses three set of filters of size [512, 512, 2048], \"f\" is 3, \"s\" is 2.\n",
    "    - The 2 identity blocks use three set of filters of size [256, 256, 2048], \"f\" is 3.\n",
    "- The 2D Average Pooling uses a window of shape (2,2).\n",
    "- The flatten doesn't have any hyperparameters.\n",
    "- The Fully Connected (Dense) layer reduces its input to the number of classes using a softmax activation.\n",
    "\n",
    "Useful links:\n",
    "\n",
    "- [Conv](https://keras.io/layers/convolutional/#conv2d)\n",
    "- [BatchNorm](https://keras.io/layers/normalization/#batchnormalization)\n",
    "- For the activation, use:  `Activation('relu')(X)`\n",
    "- [Addition](https://keras.io/layers/merge/#add)\n",
    "- [Average pooling](https://keras.io/layers/pooling/#averagepooling2d)\n",
    "- [Max pooling](https://keras.io/layers/pooling/#maxpooling2d)\n",
    "- [Zero padding](https://keras.io/layers/convolutional/#zeropadding2d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHfdszLr3k4b"
   },
   "outputs": [],
   "source": [
    "def ResNet(input_shape=(32, 32, 3), classes=10):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "\n",
    "    # Stage 1\n",
    "\n",
    "   \n",
    "    # Stage 2\n",
    "    \n",
    "\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    \n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    \n",
    "    # Stage 5 (≈3 lines)\n",
    "    \n",
    "\n",
    "    # AVGPOOL (≈1 line)\n",
    "    \n",
    "\n",
    "\n",
    "    # output layer\n",
    "   \n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=X_input, outputs=X, name='ResNe')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = ResNet(input_shape=(32, 32, 3), classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hi4WfiGnI6e1"
   },
   "source": [
    "##CIFAR10 Dataset\n",
    "\n",
    "Simply run the following code block to download and preprocess the CIFAR10 dataset. We also use online data-augmentation to improve the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dgUU9chm3k4f"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "num_classes = 10\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "datagen.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0N36L7P9J1UA"
   },
   "source": [
    "##Compile the Model\n",
    "\n",
    "The following block sets the required hyper-parameters, complies the model starts the process of training and at the end saves the trained model. \n",
    "\n",
    "You can use your own hyper-parameters, but these have been tested to work properly.\n",
    "\n",
    "Note that we require you to report the accuracy for models that have been trained for 50 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yf9YlI_LWjfW"
   },
   "outputs": [],
   "source": [
    "batch_size = 2048\n",
    "epochs = 50\n",
    "data_augmentation = True\n",
    "learning_rate=0.001\n",
    "\n",
    "opt = keras.optimizers.adam(lr=learning_rate, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "t1=time()\n",
    "history =model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                    batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)\n",
    "print('Training time is {} s'.format(time()-t1))\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "model_name='resnet'\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CuZ9pWM3KmsW"
   },
   "source": [
    "##Evaluate the model\n",
    "\n",
    "Simply run the following block of code to plot accuracies on training and validation set during different training epochs and eventually get the **accuracy** of the trained model on the **testing set** of CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LgWEKQfRdIBM"
   },
   "outputs": [],
   "source": [
    "plot_learningCurve(history,epochs)\n",
    "\n",
    "# Evaluate trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Starter.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "OEpi5",
   "launcher_item_id": "jK9EQ"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
